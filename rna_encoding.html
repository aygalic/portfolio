<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title class="jsx-f45533f31dc7e751">Encoding RNA data</title><link rel="icon" href="/portfolio/favicon.ico" class="jsx-f45533f31dc7e751"/><meta name="next-head-count" content="4"/><link rel="preload" href="/portfolio/_next/static/css/7deeff5de1ce8aa8.css" as="style"/><link rel="stylesheet" href="/portfolio/_next/static/css/7deeff5de1ce8aa8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/portfolio/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/portfolio/_next/static/chunks/webpack-e9ff99d1d13f16d3.js" defer=""></script><script src="/portfolio/_next/static/chunks/framework-49c6cecf1f6d5795.js" defer=""></script><script src="/portfolio/_next/static/chunks/main-beb9f4d71b4ad041.js" defer=""></script><script src="/portfolio/_next/static/chunks/pages/_app-5810f0a972a88d88.js" defer=""></script><script src="/portfolio/_next/static/chunks/861-9b220a6ab79a69de.js" defer=""></script><script src="/portfolio/_next/static/chunks/pages/rna_encoding-c177be7a40651852.js" defer=""></script><script src="/portfolio/_next/static/CyoxKt1-7rGlQ5fkvRIjD/_buildManifest.js" defer=""></script><script src="/portfolio/_next/static/CyoxKt1-7rGlQ5fkvRIjD/_ssgManifest.js" defer=""></script><style id="__jsx-f45533f31dc7e751">html,body{padding:0;margin:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}</style></head><body><div id="__next"><div class="jsx-f45533f31dc7e751 Home_container__d256j"><header class="header_header__OaHfl"><nav class="header_nav__q1mtj"><a class="header_homeLink__zzaFd" href="/portfolio">Home</a></nav></header><main class="jsx-f45533f31dc7e751 Home_main__VkIEL"><h1 class="jsx-f45533f31dc7e751 Home_title__hYX6j">Encoding RNA data.</h1><p class="jsx-f45533f31dc7e751 Home_description__uXNdx">The evolution of the latent representation of BRCA data throughout the training procedure!</p><h2 class="jsx-f45533f31dc7e751">Background</h2><p class="jsx-f45533f31dc7e751 Home_text__FLP25">Transcriptomic (RNAseq) data is very high dimensional and difficult to deal with using classical statistical techniques. Autoencoder, a kind of neural network that focuses on reconstructing the input through a bottleneck have been of tremendous help tackling this issue. They enable us to work with smaller representations, enabling subsequent stratification, inference and visualizations.</p><h2 class="jsx-f45533f31dc7e751">Method</h2><p class="jsx-f45533f31dc7e751 Home_text__FLP25">I implemented a highly modular auto encoder approach where different part can be swapped out, assessing the performance of multiple approaches. Such modules go from the type of layers we use (conventional multi layer perceptron (MLP), as well as convolutional neural network (CNN)) to the type of latent space we implement. The following approach were considered : No variational approach, Variational Autoencoder (VAE) and Vector-Quantized VAE (VQ-VAE).</p><h2 class="jsx-f45533f31dc7e751">Results</h2><iframe src="https://aygalic.github.io/biosequence_encoding/pca_animation.html" title="description" class="jsx-f45533f31dc7e751 Home_subframe__T0sZp"></iframe><p class="jsx-f45533f31dc7e751 Home_text__FLP25">Each point correspond to the patient representation through the encoder at different steps of the training process. This is achieved by training an auto encoder over RNAseq data from ~1200 patients provided openly by the TCGA project. At a given set of steps, we compute the PCA projection of the latent representation of the whole dataset and then put everything together in a nice smooth animation.</p><h2 class="jsx-f45533f31dc7e751">Going further</h2><p class="jsx-f45533f31dc7e751 Home_text__FLP25">Some automatic parameter search methods have been implemented. This was the goal of my thesis, where I assess the clustering capabilities on one dataset with a set of hyperparameter. I would then use those same hyper parameters on a different set, with similar processing steps, hoping to discover an underlying structure within the target dataset.<br class="jsx-f45533f31dc7e751"/><br class="jsx-f45533f31dc7e751"/>You can find the code used to build this dynamic representation and more <a href="https://github.com/aygalic/biosequence_encoding/" class="jsx-f45533f31dc7e751">on my github</a> as well as its <a href="https://aygalic.github.io/biosequence_encoding/" class="jsx-f45533f31dc7e751">documentation</a>.</p></main><footer class="jsx-f45533f31dc7e751 Home_footer__yFiaX"><p class="jsx-f45533f31dc7e751">Built with Next.js</p></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/rna_encoding","query":{},"buildId":"CyoxKt1-7rGlQ5fkvRIjD","assetPrefix":"/portfolio","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>